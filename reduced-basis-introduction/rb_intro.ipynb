{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caa6dfc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "# enable logging widget\n",
    "%load_ext pymor.tools.jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86f5b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".rise-enabled .jp-RenderedHTMLCommon table {\n",
    "         font-size: 150%;\n",
    "}\n",
    "\n",
    ".rise-enabled .jp-RenderedHTMLCommon p {\n",
    "    font-size: 1.5rem;\n",
    "}\n",
    "\n",
    ".rise-enabled .jp-RenderedHTMLCommon li {\n",
    "    font-size: 1.5rem;\n",
    "}\n",
    "\n",
    "\n",
    ".rise-enabled .jp-RenderedHTMLCommon h2 {\n",
    "    font-size: 2.9rem;\n",
    "    font-weight: bold;\n",
    "}\n",
    "\n",
    ".rise-enabled .jp-RenderedHTMLCommon h3 {\n",
    "    font-size: 2.0rem;\n",
    "    font-weight: bold;\n",
    "}\n",
    "\n",
    ".rise-enabled .jupyter-widget-Collapse-header {\n",
    "    font-size: 1rem;\n",
    "}\n",
    "\n",
    ".rise-enabled .jupyter-widget-Collapse-header i{\n",
    "    font-size: 1rem;\n",
    "}\n",
    "\n",
    ".rise-enabled .cm-editor {\n",
    "    font-size: 1.25rem;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b04605",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reduced Basis Methods with pyMOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f276b0f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "## Our Goal\n",
    "\n",
    "We want to do model order reduction (MOR) for parametric problems.\n",
    "\n",
    "This means:\n",
    "\n",
    "- We are given a full-order model (FOM), usually a PDE model, which depends on some set of parameters $\\mu \\in \\mathbb{R}^Q$.\n",
    "- We can simulate/solve the FOM for any given $\\mu$. But this is costly.\n",
    "- We want to simulate the model for many different $\\mu$.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- Replace the FOM by a surrogate reduced-order model (ROM).\n",
    "- The ROM should be much faster to simulate/solve.\n",
    "- The error between the ROM and FOM solution should be small and controllable.\n",
    "\n",
    "Note: In this tutorial we will only cover the mere basics of reduced basis (RB) methods. The approach has been extended to other types of models (systems, non-linear, inf-sup stable, outputs, ...) and is largely independent of the specific choice of discretization method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a0a66",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building the FOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1dd544",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Thermal-block problem\n",
    "\n",
    "Find $u(x,\\mu)$ for $\\mu\\in\\mathcal{P}$ such that\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "-\\nabla \\cdot [d(x, \\mu) \\nabla u(x,\\mu)] &= f(x) & x &\\in \\Omega, \\\\\n",
    "u(x,\\mu) &= 0 & x &\\in \\partial \\Omega,\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $\\Omega := [0,1]^2 = \\Omega_1 \\cup \\Omega_2 \\cup \\Omega_3 \\cup \\Omega_4$, $f \\in L^2(\\Omega)$,\n",
    "\n",
    "\n",
    "$$\n",
    "d(x, \\mu) \\equiv \\mu_i \\quad x \\in \\Omega_i\n",
    "$$\n",
    "\n",
    "and $\\mu \\in [\\mu_{\\min}, \\mu_{\\max}]^4$.\n",
    "\n",
    "\n",
    "```\n",
    "        (0,1)-----------------(1,1)\n",
    "        |            |            |\n",
    "        |            |            |\n",
    "        |     μ_2    |     μ_3    |\n",
    "        |            |            |\n",
    "        |            |            |\n",
    "        |--------------------------\n",
    "        |            |            |\n",
    "        |            |            |\n",
    "        |     μ_0    |     μ_1    |\n",
    "        |            |            |\n",
    "        |            |            |\n",
    "        (0,0)-----------------(1,0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd2dbb4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Setting up an analytical description of the thermal block problem\n",
    "\n",
    "The thermal block problem already comes with pyMOR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c0aa5b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "from pymor.basic import *\n",
    "p = thermal_block_problem([2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5db8ff0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our problem is parameterized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45eede8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "p.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd56df72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Looking at the definition\n",
    "\n",
    "We can easily look at the definition of `p` by printing its `repr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8484e068",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec0a86",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "It is easy to [build custom problem definitions](https://docs.pymor.org/latest/tutorial_builtin_discretizer.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8ae89b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Weak formulation\n",
    "\n",
    "Find $u(\\mu) \\in H^1_0(\\Omega)$ such that\n",
    "\n",
    "$$\n",
    "\\underbrace{\\int_\\Omega d(x, \\mu(x)) \\nabla u(x, \\mu) \\cdot \\nabla v(x) \\,dx}\n",
    "    _{=:a(u(\\mu), v; \\mu)}\n",
    "= \\underbrace{\\int_\\Omega f(x)v(x) \\,dx}\n",
    "    _{=:\\ell(v)}\n",
    "    \\qquad \\forall v \\in H^1_0(\\Omega).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67921481",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Galerkin projection onto finite-element space\n",
    "\n",
    "Let $\\mathcal{T}_h$ be an admissible triangulation of $\\Omega$ and $V_h:=\\mathcal{S}_{h,0}^1(\\mathcal{T}_h)$ the corresponding space of piece-wise linear finite-element functions over $\\mathcal{T}_h$ which vanish at $\\partial\\Omega$.\n",
    "The finite-element approximation $u_h(\\mu) \\in V_h$ is then given by\n",
    "\n",
    "\n",
    "$$\n",
    "    a(u_h(\\mu), v_h;\\mu) = \\ell(v_h)\n",
    "    \\qquad \\forall v_h \\in V_h.\n",
    "$$\n",
    "\n",
    "Céa's Lemma states that $u_h(\\mu)$ is a quasi-best approximation of $u(\\mu)$ in $V_h$:\n",
    "\n",
    "$$\n",
    "    \\|\\nabla u(\\mu) - \\nabla u_h(\\mu)\\|_{L^2(\\Omega)}\n",
    "    \\leq \\frac{\\mu_{max}}{\\mu_{min}} \\inf_{v_h \\in V_h} \\|\\nabla u(\\mu) - \\nabla v_h\\|_{L^2(\\Omega)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed37a1ce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Linear system assembly\n",
    "\n",
    "Let $\\varphi_{h,1}, \\ldots, \\varphi_{h,n}$ be the finite-element basis of $\\mathcal{S}_{h,0}^1(\\mathcal{T}_h)$.\n",
    "Let $A(\\mu) \\in \\mathbb{R}^{n\\times n}$, $\\underline{\\ell} \\in \\mathbb{R}^n$ be given by\n",
    "\n",
    "$$\n",
    "    A(\\mu)_{j,i} := a(\\varphi_{h,i}, \\varphi_{h,j};\\mu) \\qquad\n",
    "    \\underline \\ell_j := \\ell(\\varphi_{h,j}).\n",
    "$$\n",
    "\n",
    "Then with\n",
    "$$\n",
    "    u_h(\\mu) = \\sum_{i=1}^{n} \\underline{u}_h(\\mu)_i \\cdot \\varphi_{h,i},\n",
    "$$\n",
    "\n",
    "we get\n",
    "\n",
    "$$\n",
    "    A(\\mu) \\cdot \\underline{u}_h(\\mu) = \\underline{\\ell}.\n",
    "$$\n",
    "\n",
    "Note that $A(\\mu)$ is a sparse matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898167ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### FOM assembly with pyMOR\n",
    "\n",
    "We use the builtin discretizer `discretize_stationary_cg` to compute a finite-element discretization of the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8976612",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "fom, data = discretize_stationary_cg(p, diameter=1/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2170975e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`fom` is a `Model`. It has the same `Parameters` as `p`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac96fc6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "fom.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a164fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.discretizers.builtin.cg import InterpolationOperator\n",
    "diffusion_field_1 = InterpolationOperator(data['grid'], p.diffusion).as_vector(fom.parameters.parse({'diffusion': [1., 0.01, 0.1, 1.]}))\n",
    "diffusion_field_2 = InterpolationOperator(data['grid'], p.diffusion).as_vector(fom.parameters.parse({'diffusion': [0.02, 1.5, 0.3, 0.01]}))\n",
    "fom.visualize((diffusion_field_1, diffusion_field_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26811fb6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Solving the FOM\n",
    "\n",
    "To `solve` the FOM, we need to specify values for those parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a74a866",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "U = fom.solve({'diffusion': [1., 0.01, 0.1, 1.]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c941cbbc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`U` is a `VectorArray`, an ordered collection of vectors of the same dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff03f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dcb892",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "`U` only contains a single vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b291e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "len(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a1094",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "For a time-dependent problem, `U` would have contained a time-series of vectors. `U` corresponds to the coefficient vector $\\underline{u}_h(\\mu)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3851d70f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Looking at the solution\n",
    "\n",
    "We can use the `visualize` method to plot the solution (we also plot the solution for the second diffusivity field here for comparison):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42afbdc4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "fom.visualize((U, fom.solve({'diffusion': [0.02, 1.5, 0.3, 0.01]})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67ba81c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parameter separability\n",
    "\n",
    "Remember the special form of $a(\\cdot, \\cdot; \\mu)$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    a(u, v; \\mu) &:= \\int_\\Omega d(x, \\mu) \\nabla u(x) \\cdot \\nabla v(x) \\,dx \\\\\n",
    "    &:=\\int_\\Omega \\Bigl(\\sum_{q=1}^Q \\mu_q \\mathbf{1}_q(x)\\Bigr) \\nabla u(x) \\cdot \\nabla v(x) \\,dx \\\\\n",
    "    &:=\\sum_{q=1}^Q  \\ \\underbrace{\\mu_q}_{:=\\theta_q(\\mu)} \\ \\ \n",
    "        \\underbrace{\\int_\\Omega \\mathbf{1}_q(x) \\nabla u(x) \\cdot \\nabla v(x) \\,dx}_{=:a_q(u,v)}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Hence, $a(\\cdot, \\cdot; \\mu)$ admits the affine decomposition\n",
    "\n",
    "$$\n",
    "    a(u, v; \\mu) = \\sum_{q=1}^Q \\theta_q(\\mu) \\cdot a_q(u,v).\n",
    "$$\n",
    "\n",
    "Consequently, for $A(\\mu)$ we have the same structure:\n",
    "\n",
    "$$\n",
    "    A(\\mu) = \\sum_{q=1}^Q \\theta_q(\\mu) \\cdot A_q,\n",
    "$$\n",
    "\n",
    "where $(A_q)_{j,i} := a_q(\\varphi_{h,i}, \\varphi_{h,j})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a95f48",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parameter-separable FOM\n",
    "\n",
    "Remember that our problem definition encoded the affine decomposition of $d(x, \\mu)$ using a `LincombFunction`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a16dc7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "p.diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0925ff22",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "pyMOR's builtin `discretizer` automatically preserves this structure when assembling the system matrices. Let's look at the `fom` in more detail. The system matrix $A(\\mu)$ is stored in the `Model`'s `operator` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf796171",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "fom.operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d608cda3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "We see that the `LincombFunction` has become a `LincombOperator` of `NumpyMatrixOperators`.\n",
    "pyMOR always interprets matrices as linear `Operators`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e58dd33",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The right-hand side vector $\\underline{\\ell}$ is stored in the `rhs` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2954a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "fom.rhs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d12375f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "`fom.rhs` is not a `VectorArray` but a vector-like operator in order to support parameter-dependent right-hand sides. Only `Operators` can depend on a parameter in `pyMOR`, not `VectorArrays`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9896c8f5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Other ways of obtaining the FOM\n",
    "\n",
    "> Using an `analyticalproblem` and a `discretizer` is just one way\n",
    "  to build the FOM.\n",
    ">  \n",
    "> Everything that follows works the same for a FOM that is built using an external PDE solver."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7264e70d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reduced basis methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6bfdfa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Projection-based MOR\n",
    "\n",
    "Going back to the definition of the FOM\n",
    "\n",
    "$$\n",
    "    a(u_h(\\mu), v_h; \\mu) = \\ell(v_h) \\qquad \\forall v_h \\in V_h,\n",
    "$$\n",
    "\n",
    "our MOR approach is based on the idea of replacing the generic finite-element space $V_h$ by a problem-adapted reduced space $V_N\\subset V_h$ of low dimension. I.e., we simply define our ROM by a Galerkin projection of the solution onto the reduced space $V_N$. So the reduced approximation $u_N(\\mu) \\in V_N$ of $u_h(\\mu)\\in V_h$ is given as the solution of\n",
    "\n",
    "$$\n",
    "    a(u_N(\\mu), v_N; \\mu) = \\ell(v_N) \\qquad \\forall v_N \\in V_N.\n",
    "$$\n",
    "\n",
    "Again, we can apply Céa's Lemma:\n",
    "\n",
    "$$\n",
    "    \\|\\nabla u_h(\\mu) - \\nabla u_N(\\mu)\\|_{L^2(\\Omega)}\n",
    "    \\leq \\frac{\\mu_{max}}{\\mu_{min}} \\inf_{\\color{red}v_N \\in V_N} \\|\\nabla u_h(\\mu) - \\nabla v_N\\|_{L^2(\\Omega)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b436bd7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Does a good reduced space $V_N$ exist?\n",
    "\n",
    "Thanks to Céa's lemma, our only job is to come up with a good low-dimensional approximation space $V_N$. In RB methods, our definition of 'good' is usually that we want to miminize the worst-case best-approximation error over all parameters $\\mu \\in \\mathcal{P}$. I.e.,\n",
    "\n",
    "$$\n",
    "    \\sup_{\\mu \\in \\mathcal{P}} \\inf_{v_N \\in V_N} \\|\\nabla u_h(\\mu) - \\nabla v_N\\|_{L^2(\\Omega)}\n",
    "$$\n",
    "\n",
    "should not be much larger than the Kolmogorov $N$-width\n",
    "\n",
    "$$\n",
    "    d_N:=\\inf_{\\substack{V'_N \\subset V_h\\\\ \\dim V'_N \\leq N}}\\sup_{\\mu \\in \\mathcal{P}} \\inf_{v'_N \\in V'_N} \\|\\nabla u_h(\\mu) - \\nabla v'_N\\|_{L^2(\\Omega)}.\n",
    "$$\n",
    "\n",
    "We won't go into details here, but it can be shown that for parameter-separable coercive problems like the thermal-block problem, the Kolmogorov $N$-widths decay at a subexponential rate, so good reduced spaces $V_N$ of small dimension $N$ do exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68741083",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Snapshot-based MOR\n",
    "\n",
    "The question remains how to find a good $V_N$ algorithmically. RB methods are snapshot based which means that $V_N$ is constructed from 'solution snapshots' $u_{h}(\\mu_i)$ of the FOM, i.e.\n",
    "\n",
    "$$\n",
    "    V_N \\subset \\operatorname{span} \\{u_h(\\mu_1), \\ldots, u_h(\\mu_n)\\}.\n",
    "$$\n",
    "\n",
    "We will start by just randomly picking some snapshot parameters $\\mu_i\\in\\mathcal{P}$ for $i=1,\\dots,N$ with $N=10$ and set $V_N=\\operatorname{span}\\{u_h(\\mu_1), \\ldots, u_h(\\mu_N)\\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c23b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "snapshot_parameters = p.parameter_space.sample_randomly(10)\n",
    "snapshots = fom.solution_space.empty()\n",
    "for mu in snapshot_parameters:\n",
    "    snapshots.append(fom.solve(mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1b103e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For numerical stability, it's a good idea to orthonormalize the basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69290ed9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "basis = gram_schmidt(snapshots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6777ea36",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Is our basis any good?\n",
    "\n",
    "Let's see if we actually constructed a good approximation space by computing the best-approximation error in this space for some further random solution snapshot. We can do so via orthogonal projection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3e7573",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "mu = p.parameter_space.sample_randomly()\n",
    "U_test = fom.solve(mu)\n",
    "coeffs = basis.inner(U_test)\n",
    "U_test_proj = basis.lincomb(coeffs)\n",
    "fom.visualize((U_test, U_test_proj, U_test-U_test_proj),\n",
    "              legend=('U', 'projection', 'error'),\n",
    "              separate_colorbars=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e386c9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's also compute the relative norm of the error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f991dc1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "(U_test - U_test_proj).norm().item() / U_test.norm().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcef04d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Assembling the reduced system matrix\n",
    "\n",
    "In order to compute a reduced solution, we need to choose a reduced basis $\\psi_{1}, \\ldots, \\psi_{N}$ of $V_N$ and assemble the reduced system matrix $A_{N}(\\mu) \\in \\mathbb{R}^{N\\times N}$ and right-hand side vector $\\underline{\\ell}_N \\in \\mathbb{R}^N$ given by\n",
    "\n",
    "$$\n",
    "    A_N(\\mu)_{j,i} := a(\\psi_i, \\psi_j; \\mu) \\qquad\\text{and}\\qquad\n",
    "    \\underline{\\ell}_{N,j} := \\ell(\\psi_j).\n",
    "$$\n",
    "\n",
    "Expanding each basis vector $\\psi_i$ w.r.t. the finite-element basis $\\varphi_{h,i}$,\n",
    "\n",
    "$$\n",
    "    \\psi_i = \\sum_{k=1}^N \\underline{\\psi}_{i,k} \\varphi_{h,k},\n",
    "$$\n",
    "\n",
    "we get\n",
    "\n",
    "$$\n",
    "    A_N(\\mu)_{i,j} = \\underline{\\psi}_i^{\\operatorname{T}} \\cdot A(\\mu) \\cdot \\underline{\\psi}_j\n",
    "$$\n",
    "\n",
    "or more compactly written as\n",
    "\n",
    "$$\n",
    "    A_N(\\mu) = \\underline{V}^{\\operatorname{T}} \\cdot A(\\mu) \\cdot \\underline{V},\n",
    "$$\n",
    "\n",
    "where the columns of $\\underline{V}\\in\\mathbb{R}^{n\\times N}$ are given by the basis vectors $\\psi_{1},\\dots,\\psi_{N}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd13313",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Thus, we could compute $A_N(\\mu)$ in pyMOR using `W = fom.operator.apply(basis, mu=mu)` (multiplication from the right) and then using `basis.inner(W)` to multiply the basis from the left. We can use the `apply2` method as a (potentially more efficient) shorthand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f0e8f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "A_N = fom.operator.apply2(basis, basis, mu=mu)\n",
    "A_N.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9006941",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "Note that, contrary to the finite-element system matrix $A(\\mu)$, the reduced matrix $A_N(\\mu)$ is a dense but small matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb4af1d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Assembling the reduced right-hand side\n",
    "\n",
    "For the right-hand side we have\n",
    "\n",
    "$$\n",
    "    \\underline{\\ell}_{N,j} = \\underline{\\psi}_j^{\\operatorname{T}} \\cdot \\underline{\\ell}\n",
    "$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\n",
    "    \\underline{\\ell}_{N} = \\underline{V}^{\\operatorname{T}} \\cdot \\underline{\\ell},\n",
    "$$\n",
    "\n",
    "which we compute using `inner`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0fb9c9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "l_N = basis.inner(fom.rhs.as_vector())\n",
    "l_N.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50262330",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Solving the reduced system\n",
    "\n",
    "Finally, writing\n",
    "\n",
    "$$\n",
    "    u_N(\\mu) = \\sum_{i=1}^N \\underline{u}_N(\\mu)_i \\cdot \\psi_i\n",
    "$$\n",
    "\n",
    "we have\n",
    "\n",
    "$$\n",
    "    A_N(\\mu) \\cdot \\underline{u}_N(\\mu) = \\underline{\\ell}_N\n",
    "$$\n",
    "\n",
    "or equivalently\n",
    "\n",
    "$$\n",
    "    \\underline{V}^{\\operatorname{T}} \\cdot A(\\mu) \\cdot \\underline{V}\\cdot \\underline{u}_N(\\mu) = \\underline{V}^{\\operatorname{T}} \\cdot \\underline{\\ell}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bdacaa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So, let's solve the linear system and compare the reduced solution to the FOM solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ef16aa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "u_N = np.linalg.solve(A_N, l_N)\n",
    "U_N = basis.lincomb(u_N.ravel())\n",
    "U = fom.solve(mu)\n",
    "fom.visualize((U, U_N, U-U_N),\n",
    "              legend=('FOM', 'ROM', 'Error'),\n",
    "              separate_colorbars=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d907703",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's also compute the relative norm of the error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a9f2b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "(U - U_N).norm().item() / U.norm().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581c1e0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Automatic structure-preserving operator projection\n",
    "\n",
    "For each new parameter $\\mu$ we want to solve the ROM for, we have to assemble a new $A_N(\\mu)$, which requires $\\mathcal{O}(N^2)$ high-dimensional operations. This can significantly diminish the efficiency of our ROM. However, we can avoid this issue by exploiting the parameter separability of $A(\\mu)$,\n",
    "\n",
    "$$\n",
    "    A(\\mu) = \\sum_{q=1}^Q \\theta_q(\\mu) \\cdot A_q,\n",
    "$$\n",
    "\n",
    "which is inherited by $A_N(\\mu)$:\n",
    "\n",
    "$$\n",
    "    A_N(\\mu) = \\sum_{q=1}^Q \\theta_q(\\mu) \\cdot A_{N,q},\n",
    "$$\n",
    "where $(A_{N,q})_{i,j} = \\underline{\\psi}_i^{\\operatorname{T}} \\cdot A_q \\cdot \\underline{\\psi}_j$ and $A_{N,q}=\\underline{V}^{\\operatorname{T}}\\cdot A_q \\cdot \\underline{V}$.\n",
    "\n",
    "Thus, we have to project all operators in `fom.operator.operators` individually and then later form a linear combination of these matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b6a22",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is getting tedious, so we let pyMOR do the work for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90f0a9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "op_N = project(fom.operator, basis, basis)\n",
    "op_N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33f9ea6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Similarly, we can project the right-hand side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b9bc7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "rhs_N = project(fom.rhs, basis, None)\n",
    "rhs_N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83172cb4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we could assemble a matrix operator from `op_N` for a specific `mu` using the `assemble` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4888334a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "op_N_mu = op_N.assemble(mu)\n",
    "op_N_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f81a592",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "Then, we can extract it's system matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc1534",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "op_N_mu.matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4020fc1e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "From that, we can proceed as before. However, it is more convenient, to use the operator's `apply_inverse` method to invoke an (`Operator`-dependent) linear solver with a given input `VectorArray` as right-hand side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d771379",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "u_N_new = op_N.apply_inverse(rhs_N.as_vector(), mu=mu)\n",
    "u_N_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c687ea04",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that the result is a `VectorArray`. For `NumpyVectorArray` and some other `VectorArray` types, we can extract the internal data using the `to_numpy` method. We use it to check whether we arrived at the same solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb352e40",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "np.linalg.norm(u_N.ravel() - u_N_new.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0b4147",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Projecting the entire Model\n",
    "\n",
    "In pyMOR, ROMs are built using a `Reductor` which appropriately projects all of the `Models` operators and returns a reduced `Model` comprised of the projected `Operators`. Let's pick the most basic `Reductor`\n",
    "available for a `StationaryModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf4e5ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "reductor = StationaryRBReductor(fom, basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2368b4e6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "Every reductor has a `reduce` method, which builds the ROM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b7e73",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "rom = reductor.reduce()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed93f4a7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's compare the structure of the FOM and of the ROM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f727ab19",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "fom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c379413e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2541fb6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Solving the ROM\n",
    "\n",
    "To solve the ROM, we just use `solve` again,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc22037",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "u_rom = rom.solve(mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a74f50",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "to get the reduced coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abbe098",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "u_rom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00cc78f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "It is the same coefficient vector we have computed before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efdd59c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "(u_rom - u_N_new).norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eae8bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A high-dimensional representation is obtained from the `reductor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd42de6a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "U_rom = reductor.reconstruct(u_rom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbb5c26",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Computing the MOR error\n",
    "\n",
    "Let's compute the error again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45144e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "U = fom.solve(mu)\n",
    "ERR = U - U_rom\n",
    "ERR.norm() / U.norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ada87",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492da2e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "fom.visualize(ERR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f7e0f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Proper orthogonal decomposition for reduced basis construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd442c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Extracting dominant directions in high-dimensional data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff544f3",
   "metadata": {},
   "source": [
    "Proper orthogonal decomposition (POD) is a standard method in order to compress a set of high-dimensional vectors by approximation in a suitable low-dimensional subspace. In other disciplines it is also known (up to minor adjustments) under names like Karhunen-Loève transform or principal component analysis (PCA). The approximation space $V_N$ is computed purely based on the available snapshot data (without any information about the FOM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5dc147",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Given a set of training snapshots $u^1=u_h(\\mu_1),\\dots,u^n=u_h(\\mu_n)\\in V_h$, the method aims at minimizing the mean squared projection error of the space $V_N$ on the training set:\n",
    "\n",
    "$$\n",
    "    V_N = \\underset{\\substack{V'_N \\subset V_h\\\\ \\dim V'_N \\leq N}}{\\operatorname{argmin}} \\frac{1}{n}\\sum\\limits_{i=1}^{n} \\lVert u^i - P_{V'_N}(u^i) \\rVert^2,\n",
    "$$\n",
    "\n",
    "where $P_{V'_N}(u^i)$ denotes the orthogonal projection of $u^i$ onto $V'_N$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a0f6a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In pratice, POD is usually computed using a singular value decomposition (SVD) and returns an orthonormal basis of $V_N$ (i.e. no additional orthonormalization required)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271e29a9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### POD applied in the thermalblock example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ebd8fd",
   "metadata": {},
   "source": [
    "We first compute a larger set of solution snapshots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f180a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_parameters = p.parameter_space.sample_randomly(50)\n",
    "snapshots = fom.solution_space.empty()\n",
    "for mu in snapshot_parameters:\n",
    "    snapshots.append(fom.solve(mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4d6f5f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we can run the `pod`-algorithm and construct a corresponding `reductor` as well as a reduced model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deb1460",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_basis, svals = pod(snapshots, rtol=1e-7)\n",
    "reductor = StationaryRBReductor(fom, pod_basis)\n",
    "rom = reductor.reduce()\n",
    "\n",
    "rom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9424cdad",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let us look at the singular values (coming from the SVD and providing a measure for the approximation quality of a reduced space of the respective dimension) and their decay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.semilogy(svals / svals[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09607ff",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And finally, let us compute the error for our sample parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c751a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_rom = rom.solve(mu)\n",
    "U_rom = reductor.reconstruct(u_rom)\n",
    "U = fom.solve(mu)\n",
    "ERR = U - U_rom\n",
    "ERR.norm() / U.norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a4697e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Is it actually faster?\n",
    "\n",
    "Finally, we check if our ROM is really any faster than the FOM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0c616",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "mus = p.parameter_space.sample_randomly(10)\n",
    "tic = perf_counter()\n",
    "for mu in mus:\n",
    "    fom.solve(mu)\n",
    "t_fom = perf_counter() - tic\n",
    "tic = perf_counter()\n",
    "for mu in mus:\n",
    "    rom.solve(mu)\n",
    "t_rom = perf_counter() - tic\n",
    "print(f'Speedup: {t_fom/t_rom}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5fdc9e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Large datasets\n",
    "\n",
    "> For very big datasets, for instance from instationary problems, a hierarchical and approximate variant of POD, called **HaPOD**, is available, see https://docs.pymor.org/main/autoapi/pymor/algorithms/hapod/index.html#module-pymor.algorithms.hapod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe25fb6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Certified Reduced Basis Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8663c675",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Error estimator\n",
    "Model order reduction introduces an additional approximation error which we need to control in order to be able to use a ROM as a reliable surrogate for a given FOM. While Céa's lemma provides a rigorous a priori bound, this error bound is not computable in general. Instead, we use a residual-based a posteriori error estimator. As in a posteriori theory for finite-element methods, we have:\n",
    "\n",
    "$$\n",
    "    \\|\\nabla u_h(\\mu) - \\nabla u_N(\\mu)\\|_{L^2(\\Omega)}\n",
    "    \\leq \\frac{1}{\\mu_{min}} \\sup_{v_h\\in V_h} \\frac{\\ell(v_h) - a(u_N(\\mu), v_h; \\mu)}{\\|\\nabla v_h\\|_{L^2(\\Omega)}}.\n",
    "$$\n",
    "\n",
    "For this estimate to hold, it is crucial that we use the right norms. I.e., instead of the Euclidean norm of the coefficient vectors, which we have used so far, we need to use the $H^1$-seminorm. \n",
    "\n",
    "The inner product matrix of the $H^1$-seminorm is automatically assembled by pyMOR's builtin discretizer and available as `fom.h1_0_semi_product`. We can pass it as the `product`-argument to methods like `norm`, `inner` or `gram_schmidt` to perform these operations w.r.t. the correct inner product/norm. Further, we need a lower bound for the coercivity constant of $a(\\cdot, \\cdot; \\mu)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32452cf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Using this information, we can replace `StationaryRBReductor` by `CoerciveRBReductor`, which will add a reduction-error estimator to our ROM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf625ac0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "basis = gram_schmidt(snapshots, product=fom.h1_0_semi_product)\n",
    "reductor = CoerciveRBReductor(\n",
    "    fom,\n",
    "    basis,\n",
    "    product=fom.h1_0_semi_product,\n",
    "    coercivity_estimator=ExpressionParameterFunctional('min(diffusion)', fom.parameters)\n",
    ")\n",
    "rom = reductor.reduce()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fdb3f6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We won't go into details here, but an 'offline-online decomposition' of the error estimator is possible similar to what we did for the projection of the system operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539d3b80",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "rom.error_estimator.residual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e83bb04",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's check if the estimator works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a1b30",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "U = fom.solve(mu)\n",
    "u_N = rom.solve(mu)\n",
    "est = rom.estimate_error(mu).item()\n",
    "err = (U - reductor.reconstruct(u_N)).norm(product=fom.h1_0_semi_product).item()\n",
    "print(f'error: {err}, estimate: {est}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01529f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Greedy basis generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9806074",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So far, we have built the reduced space $V_N$ by just randomly picking snapshot parameters. A theoretically well-founded approach which leads to quasi-optimal approximation spaces it the so-called weak greedy algorithm. In the weak greedy algorithm, $V_N$ is constructed iteratively by enlarging $V_N$ by an element $u_h(\\mu_{N+1})$ such that\n",
    "\n",
    "$$ \\inf_{v_N \\in V_N} \\|\\nabla u_h(\\mu_{N+1}) - \\nabla v_N\\|_{L^2(\\Omega)}\n",
    "\\geq C \\cdot \\sup_{\\mu \\in \\mathcal{P}}\\inf_{v_N \\in V_N} \\|\\nabla u_h(\\mu) - \\nabla v_N\\|_{L^2(\\Omega)}, $$\n",
    "\n",
    "for some fixed constant $0 < C \\leq 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2fa79e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In RB methods, we find such a $\\mu_{N+1}$ by picking the parameter for which the estimated reduction error is maximized. \n",
    "\n",
    "In order to make this maximization procedure computationally feasible, the infinite set $\\mathcal{P}$ is replaced by a finite subset of training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a57308",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "training_set = p.parameter_space.sample_uniformly(4)\n",
    "len(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c83d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given this training set, we can use `rb_greedy` to compute $V_N$. In order to start with an empty basis, we create a new reductor that, by default, is initialized with an empty basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3c7df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "reductor = CoerciveRBReductor(\n",
    "    fom,\n",
    "    product=fom.h1_0_semi_product,\n",
    "    coercivity_estimator=ExpressionParameterFunctional('min(diffusion)', fom.parameters)\n",
    ")\n",
    "greedy_data = rb_greedy(fom, reductor, training_set, max_extensions=20)\n",
    "print(greedy_data.keys())\n",
    "rom = greedy_data['rom']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5da312",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Testing the ROM\n",
    "\n",
    "Let's compute the error again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f605b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "mu = p.parameter_space.sample_randomly()\n",
    "U = fom.solve(mu)\n",
    "u_rom = rom.solve(mu)\n",
    "ERR = U - reductor.reconstruct(u_rom)\n",
    "ERR.norm(fom.h1_0_semi_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637e10f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and compare it with the estimated error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d967ac4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "rom.estimate_error(mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcceecd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Is it actually faster?\n",
    "\n",
    "Finally, we check if our ROM is really any faster than the FOM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861067d4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "mus = p.parameter_space.sample_randomly(10)\n",
    "tic = perf_counter()\n",
    "for mu in mus:\n",
    "    fom.solve(mu)\n",
    "t_fom = perf_counter() - tic\n",
    "tic = perf_counter()\n",
    "for mu in mus:\n",
    "    rom.solve(mu)\n",
    "t_rom = perf_counter() - tic\n",
    "print(f'Speedup: {t_fom/t_rom}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e5fc1",
   "metadata": {},
   "source": [
    "**Important note:** In contrast to POD, the FOM is **not** solved for all training parameters, but only for selected ones!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550df4c9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some possible exercises\n",
    "\n",
    "- Plot the MOR error vs. the dimension of the reduced space. (Use `reductor.reduce(N)` to project onto a sub-basis of dimension `N`.)\n",
    " \n",
    "- Plot the speedup vs. the dimension of the reduced space.\n",
    "\n",
    "- Compute the maximum/minimum efficiency of the error estimator over the parameter space.\n",
    "\n",
    "- Try different numbers of subdomains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16f7358",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Instationary problems and POD-greedy\n",
    "\n",
    "We are interested in solving a time-dependent problem of the form\n",
    "\n",
    "$$\n",
    "    (\\partial_t u_h(\\mu),v_h)_{L^2} + a(u_h(\\mu), v_h;\\mu) = \\ell(v_h)\n",
    "    \\qquad \\forall v_h \\in V_h,\n",
    "$$\n",
    "\n",
    "where $u_h(\\mu)\\colon[0,T]\\to V_h$ is now a function of time. Discretization in time using the implicit Euler scheme with step size $\\Delta t>0$ yields\n",
    "\n",
    "$$\n",
    "    (m + \\Delta t\\cdot a)(u_{h,n+1}(\\mu),v_h) = \\Delta t\\cdot l(v_h) + m(u_{h,n},v_h) \\qquad \\forall v_h \\in V_h,\n",
    "$$\n",
    "\n",
    "where $m(u,v)=(u,v)_{L^2}$ is a mass operator. A single step of the time stepping scheme therefore looks similar to an elliptic problem and we can - given a suitable reduced basis - apply projection-based MOR as before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a82c0bf",
   "metadata": {},
   "source": [
    "### How to compute a reduced basis?\n",
    "\n",
    "In the time-dependent case, the solution to every parameter consists of a whole trajectory in time. Hence, running a greedy algorithm and adding the complete trajectory to the reduced basis in every step is not a good idea! Moreover, due to error accumulation over time, selecting a suitable time step in a greedy fashion is also tricky (some heuristics exist though), i.e. doing a greedy in parameter and time is usually difficult. On the other hand, computing a POD of many (potentially long) trajectories can become computationally infeasible very quickly as well.\n",
    "\n",
    "The POD-greedy method combines both approaches by **compressing the projection error** of the trajectory corresponding to the **selected parameter** in every step of the greedy algorithm. Typically, only a small number of modes (often actually only a single one) is then added to the reduced basis in every greedy iteration.\n",
    "\n",
    "In pyMOR, the greedy algorithm performs this compression of projection errors automatically (within the `extend_basis` method of the respective reductor) without requiring any adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecfc286",
   "metadata": {},
   "source": [
    "### Example of a parametric heat equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4adb0f",
   "metadata": {},
   "source": [
    "Consider on the spatial domain $\\Omega=[0,1]^2$ and the time interval $[0,1]$ the following parabolic equation with a high-conductivity and two parametrized channels ($\\mathcal{P}=[1,100]$):\n",
    "$$\n",
    "    \\partial_t u(\\mu) - \\nabla (d(\\mu)\\nabla u(\\mu)) = f(t)\n",
    "$$\n",
    "with parametric diffusivity\n",
    "$$\n",
    "    d(\\mu) = 1 + \\underbrace{99\\cdot\\mathbf{1}_{(0.45,0.55)\\times(0,0.7)}}_{\\text{high-conductivity channel}} + (\\mu - 1)\\cdot(\\underbrace{\\mathbf{1}_{(0.35,0.4)\\times(0.3,1)}+\\mathbf{1}_{(0.6,0.65)\\times(0.3,1)}}_{\\text{parametrized channels}}),\n",
    "$$\n",
    "time-dependent right-hand side\n",
    "$$\n",
    "    f(t) = 100\\cdot\\sin(10\\pi t)\n",
    "$$\n",
    "and Neumann boundary condition\n",
    "$$\n",
    "    \\partial_n u(\\mu, t, (x,y))=\\begin{cases}-1000 & 0.45 < x < 0.55\\\\0 & \\text{else}\\end{cases}\n",
    "$$\n",
    "at the bottom of the domain ($\\Gamma_{\\text{bottom}}=[0,1]\\times\\{0\\}$) and homogeneous Dirichlet boundary conditions everywhere else.\n",
    "The initial condition is set to\n",
    "$$\n",
    "    u(\\mu, 0) = 10\\cdot \\mathbf{1}_{(0.45,0.55)\\times(0,0.7)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefcd95a",
   "metadata": {},
   "source": [
    "We create this example using pyMOR's builtin discretizer (the FOM for this example is also directly available in `pymor/models/examples.py`, however we also need the problem definition and the discretization data here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_intervals = 50\n",
    "nt = 50\n",
    "\n",
    "from pymor.analyticalproblems.domaindescriptions import RectDomain\n",
    "from pymor.analyticalproblems.elliptic import StationaryProblem\n",
    "from pymor.analyticalproblems.functions import ConstantFunction, ExpressionFunction, LincombFunction\n",
    "from pymor.analyticalproblems.instationary import InstationaryProblem\n",
    "from pymor.discretizers.builtin import discretize_instationary_cg\n",
    "from pymor.parameters.functionals import ExpressionParameterFunctional\n",
    "\n",
    "# setup analytical problem\n",
    "problem = InstationaryProblem(\n",
    "\n",
    "    StationaryProblem(\n",
    "        domain=RectDomain(top='dirichlet', bottom='neumann'),\n",
    "\n",
    "        diffusion=LincombFunction(\n",
    "            [ConstantFunction(1., dim_domain=2),\n",
    "             ExpressionFunction('(0.45 < x[0] < 0.55) * (x[1] < 0.7) * 1.',\n",
    "                                dim_domain=2),\n",
    "             ExpressionFunction('(0.35 < x[0] < 0.40) * (x[1] > 0.3) * 1. + '\n",
    "                                '(0.60 < x[0] < 0.65) * (x[1] > 0.3) * 1.',\n",
    "                                dim_domain=2)],\n",
    "            [1.,\n",
    "             100. - 1.,\n",
    "             ExpressionParameterFunctional('top[0] - 1.', {'top': 1})]\n",
    "        ),\n",
    "\n",
    "        rhs=ConstantFunction(value=100., dim_domain=2) * ExpressionParameterFunctional('sin(10*pi*t[0])', {'t': 1}),\n",
    "\n",
    "        dirichlet_data=ConstantFunction(value=0., dim_domain=2),\n",
    "\n",
    "        neumann_data=ExpressionFunction('(0.45 < x[0] < 0.55) * -1000.', dim_domain=2),\n",
    "    ),\n",
    "\n",
    "    T=1.,\n",
    "\n",
    "    initial_data=ExpressionFunction('(0.45 < x[0] < 0.55) * (x[1] < 0.7) * 10.', dim_domain=2)\n",
    ")\n",
    "\n",
    "# discretize using continuous finite elements\n",
    "fom, data = discretize_instationary_cg(analytical_problem=problem, diameter=1./grid_intervals, nt=nt)\n",
    "\n",
    "parameter_space = fom.parameters.space(1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf514e",
   "metadata": {},
   "source": [
    "Let us look at the diffusivity field for two different parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08222448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.discretizers.builtin.cg import InterpolationOperator\n",
    "diffusion_field_1 = InterpolationOperator(data['grid'], problem.stationary_part.diffusion).as_vector(fom.parameters.parse({'top': [2.]}))\n",
    "diffusion_field_2 = InterpolationOperator(data['grid'], problem.stationary_part.diffusion).as_vector(fom.parameters.parse({'top': [100.]}))\n",
    "fom.visualize((diffusion_field_1, diffusion_field_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c6dfd",
   "metadata": {},
   "source": [
    "And the corresponding solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fom.visualize((fom.solve(2.), fom.solve(100.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5ee103",
   "metadata": {},
   "source": [
    "We make use of the `ParabolicRBReductor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b074bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coercivity_estimator = ExpressionParameterFunctional('1.', fom.parameters)\n",
    "reductor = ParabolicRBReductor(fom, product=fom.h1_0_semi_product, coercivity_estimator=coercivity_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d3ae2b",
   "metadata": {},
   "source": [
    "And apply the `rb_greedy` as before (internally, the greedy method performs a POD on the time trajectory that returns a single mode):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e40b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = parameter_space.sample_uniformly(50)\n",
    "greedy_data = rb_greedy(fom, reductor, training_set, max_extensions=10)\n",
    "rom = greedy_data[\"rom\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec88befe",
   "metadata": {},
   "source": [
    "**Note:** It is also possible to add more POD modes to the reduced basis in every greedy step by passing `extension_params={'pod_modes': k}` to the `rb_greedy`-method, where `k` is the number of modes to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80810126",
   "metadata": {},
   "source": [
    "Let us look at a reduced solution and the speedup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a27be",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = parameter_space.sample_randomly()\n",
    "tic = perf_counter()\n",
    "U = fom.solve(mu)\n",
    "t_fom = perf_counter() - tic\n",
    "tic = perf_counter()\n",
    "U_RB = reductor.reconstruct(rom.solve(mu))\n",
    "t_rom = perf_counter() - tic\n",
    "print(f\"Speedup: {t_fom / t_rom}\")\n",
    "fom.visualize((U, U_RB, U - U_RB), legend=('Detailed Solution', 'Reduced Solution', 'Error'),\n",
    "              separate_colorbars=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0587c1",
   "metadata": {},
   "source": [
    "## Nonlinear Problems with POD-DEIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db090117",
   "metadata": {},
   "source": [
    "For stationary nonlinear problems, we need to solve nonlinear discrete equations of the form\n",
    "\n",
    "$$ A(\\underline{u}_h(\\mu); \\mu) = \\underline{\\ell}.$$\n",
    "\n",
    "We can do Galerkin projection as usual, which leads to\n",
    "\n",
    "$$ \\underline{V}^{\\operatorname{T}} \\cdot A(\\underline{V}\\cdot \\underline{u}_N(\\mu); \\mu) = \\underline{V}^{\\operatorname{T}} \\cdot \\underline{\\ell}.$$\n",
    "\n",
    "However, we cannot \"precompute\" $\\underline{V}^{\\operatorname{T}} \\cdot A(\\underline{V} \\cdot (\\ldots); \\mu): \\mathbb{R}^N \\to \\mathbb{R}^N$, even for a single $\\mu$!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3666ea32",
   "metadata": {},
   "source": [
    "### (Discrete) Empirical Interpolation Method ((D)EIM)\n",
    "\n",
    "- Only evalutate\n",
    "  $$A(\\cdot; \\mu)_{i_m} \\quad\\text{for $M$ interpolation DOFs} \\quad i_1, \\ldots i_M$$\n",
    "  For FD, FV, FEM, et al., this only requires local low-dimensional computations!\n",
    "\n",
    "- Approximate\n",
    "  $$A(\\cdot; \\mu) \\approx \\sum_{m=1}^M \\hat\\psi_m \\cdot A(\\cdot; \\mu)_{i_m},$$\n",
    "  for Lagrange interpolation basis $\\hat\\psi_1, \\ldots \\hat\\psi_M$. (In practice, different basis leading to triangular interpolation matrix is used.)\n",
    "\n",
    "- Compute $i_1, \\ldots, i_M$ and $\\hat\\psi_1, \\ldots, \\hat\\psi_M$ offline from data (EI-Greedy).\n",
    "\n",
    "- Solve\n",
    "  $$\\underline{V}^{\\operatorname{T}} \\cdot \\sum_{m=1}^M \\hat\\psi_m \\cdot A(\\underline{V}\\cdot \\underline{u}_N(\\mu); \\mu)_{i_m} = \\underline{V}^{\\operatorname{T}} \\cdot \\underline{\\ell}$$\n",
    "\n",
    "- Offline-online decomposition by precomputing all products $(\\psi_i, \\hat\\psi_j)$ and storing the coefficients of $\\psi_i$ in \"neighborhoods\" of the $i_m$ (recall that $\\psi_1,\\dots,\\psi_N$ are the columns of $\\underline{V}$, i.e. the basis vectors of the reduced space)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876fc4b5",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "We solve a parameterized version of the FEniCS [nonlinear Poisson](https://fenics.readthedocs.io/projects/dolfin/en/2017.2.0/demos/nonlinear-poisson/python/demo_nonlinear-poisson.py.html) demo:\n",
    "\n",
    "$$ \n",
    "\\begin{align} \n",
    "-\\nabla \\cdot \\left[(1 + c\\cdot u(x,y;\\mu)^2) \\nabla u(x,y;\\mu)\\right] &= x\\cdot \\sin(y) & (x,y) &\\in (0,1) \\times (0,1), \\\\\n",
    "u(1, y) &= 1, \\\\\n",
    "\\nabla u(0, y) \\cdot n = \\nabla u(x, 0) \\cdot n = \\nabla u(x, 1) \\cdot n &= 0,\n",
    "\\end{align}$$\n",
    "\n",
    "where $c \\in [0, 1000]$ is our parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba2cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dolfin as df\n",
    "mesh = df.UnitSquareMesh(100, 100)\n",
    "V = df.FunctionSpace(mesh, 'CG', 2)\n",
    "\n",
    "class DirichletBoundary(df.SubDomain):\n",
    "    def inside(self, x, on_boundary):\n",
    "        return abs(x[0] - 1.0) < df.DOLFIN_EPS and on_boundary\n",
    "bc = df.DirichletBC(V, 1., DirichletBoundary())\n",
    "\n",
    "u = df.Function(V)\n",
    "v = df.TestFunction(V)\n",
    "f = df.Expression('x[0]*sin(x[1])', degree=2)\n",
    "c = df.Constant(1.)\n",
    "F = df.inner((1 + c*u**2)*df.grad(u), df.grad(v))*df.dx - f*v*df.dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd2862a",
   "metadata": {},
   "source": [
    "### pyMOR Wrapping\n",
    "To use pyMOR, we need to wrap the FEniCS objects as pyMOR `Operators`. Then, we can create generic `StationaryModel` from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2f9ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymor.bindings.fenics import FenicsOperator, FenicsVectorSpace, FenicsVisualizer\n",
    "from pymor.models.basic import StationaryModel\n",
    "from pymor.operators.constructions import VectorOperator\n",
    "\n",
    "space = FenicsVectorSpace(V)\n",
    "op = FenicsOperator(F, space, space, u, (bc,),\n",
    "                    parameter_setter=lambda mu: c.assign(mu['c'].item()),\n",
    "                    parameters={'c': 1},\n",
    "                    solver_options={'inverse': {'type': 'newton', 'rtol': 1e-6}})\n",
    "rhs = VectorOperator(op.range.zeros())\n",
    "\n",
    "fom = StationaryModel(op, rhs, visualizer=FenicsVisualizer(space))\n",
    "\n",
    "parameter_space = fom.parameters.space((0, 1000.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb5a701",
   "metadata": {},
   "source": [
    "We can solve the model and visualize the solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d946afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = fom.solve(1.)\n",
    "fom.visualize(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6991c9e0",
   "metadata": {},
   "source": [
    "### Reduction\n",
    "\n",
    "First, we need to generate snapshot data. We directly call into pyMOR's Newton algorithm, to also get the Newton residuals as additional data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = fom.solution_space.empty()\n",
    "residuals = fom.solution_space.empty()\n",
    "for mu in parameter_space.sample_uniformly(10):\n",
    "    UU, data = newton(fom.operator, fom.rhs.as_vector(), mu=mu, rtol=1e-6, return_residuals=True)\n",
    "    U.append(UU)\n",
    "    residuals.append(data['residuals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac90605a",
   "metadata": {},
   "source": [
    "`fom.operator` vanishes on the solution. So we generate the interpolation data only from the resiudals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d5a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dofs, cb, _ = ei_greedy(residuals, rtol=1e-4)\n",
    "ei_op = EmpiricalInterpolatedOperator(fom.operator, collateral_basis=cb, interpolation_dofs=dofs, triangular=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b45808",
   "metadata": {},
   "source": [
    "We compute a POD basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa9cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb, svals = pod(U, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc17935",
   "metadata": {},
   "source": [
    "Finally, we replace the operator with the interpolated operator and project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fom_ei = fom.with_(operator=ei_op)\n",
    "reductor = StationaryRBReductor(fom_ei, rb)\n",
    "rom = reductor.reduce()\n",
    "rom = rom.with_(operator=rom.operator.with_(solver_options=fom.operator.solver_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fe8b12",
   "metadata": {},
   "source": [
    "Let's see if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = parameter_space.sample_randomly()\n",
    "U = fom.solve(mu)\n",
    "U_rom = reductor.reconstruct(rom.solve(mu))\n",
    "fom.visualize(U - U_rom)\n",
    "print(f\"Relative error: {(U - U_rom).norm().item() / U.norm().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea48b4",
   "metadata": {},
   "source": [
    "### Is it faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44306fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "mus = parameter_space.sample_randomly(10)\n",
    "tic = perf_counter()\n",
    "for mu in mus:\n",
    "    fom.solve(mu)\n",
    "t_fom = perf_counter() - tic\n",
    "tic = perf_counter()\n",
    "for mu in mus:\n",
    "    rom.solve(mu)\n",
    "t_rom = perf_counter() - tic\n",
    "print(f'Speedup: {t_fom / t_rom}')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3",
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
